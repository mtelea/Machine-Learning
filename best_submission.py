# -*- coding: utf-8 -*-
"""19Nov_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18MVL778LU_vMNW8UhnKfiVW5zh4J63_6

Importarea librariilor necesare
"""

import csv
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
import pandas as pd
from sklearn import metrics
import nltk
import re
from sklearn.model_selection import KFold
nltk.download("stopwords")
from nltk.corpus import stopwords
from sklearn.svm import LinearSVC
from sklearn.metrics import confusion_matrix

"""Extargerea Datelor"""

path = ('/content/drive/MyDrive/PROIECT AI/')
trainData  = pd.read_csv(path + 'train_data.csv')
testData = pd.read_csv(path + 'test_data.csv')

"""Curatarea datelor"""

trainData.text = trainData.text.map(lambda x: re.sub(r"(@\[A-Za-z0-9]+)|([^0-9A-Za-z \t])|(\w+:\/\/\S+)|^rt|http.+?", "", x))

"""Eliminare Stopwords"""

languages_list = ['danish', 'german', 'spanish', 'italian', 'dutch']
stopwords_all_languages = [stopwords.words(x) for x in languages_list]
full_stopword_list = []
for language in stopwords_all_languages:
  for stopword in language:
    full_stopword_list.append(stopword)

trainData.text = trainData.text.map(lambda x: ' '.join([y for y in x.split() if y not in full_stopword_list]))

"""Transformarea label-urilor in corespondente numerice"""

trainData.loc[trainData['label'] == 'England', 'label'] = 0
trainData.loc[trainData['label'] == 'Ireland', 'label'] = 1
trainData.loc[trainData['label'] == 'Scotland', 'label'] = 2

train_text_data = trainData.text.to_numpy()
train_labels = trainData.label.to_numpy(dtype = int)

"""5 Fold Cross Validation """

from sklearn.model_selection import cross_val_score

splitter = KFold(n_splits=5,shuffle=True)

for train_index, valid_index in splitter.split(train_text_data,train_labels):
  x_train, x_valid = train_text_data[train_index], train_text_data[valid_index]
  y_train, y_valid = train_labels[train_index], train_labels[valid_index]
  vectorizer = TfidfVectorizer(min_df = 2,ngram_range = (1, 5))
  tfidf_train_data = vectorizer.fit_transform(x_train)
  tfidf_validation_data = vectorizer.transform(x_valid)
  cls = LinearSVC()
  cls.fit(tfidf_train_data,y_train)
  y_train_pred = cls.predict(tfidf_train_data)
  y_valid_pred = cls.predict(tfidf_validation_data)
  print(cls.score(tfidf_validation_data, y_valid))
  print(confusion_matrix(y_valid,y_valid_pred))

"""Antrenarea modelului pe toate datele de antrenare"""

vectorizer = TfidfVectorizer(min_df = 2, ngram_range = (1, 5))
tfidf_train_data = vectorizer.fit_transform(train_text_data)

cls = LinearSVC()
cls.fit(tfidf_train_data,train_labels)

"""Verificarea performantei pe datele de train"""

y_train_pred = cls.predict(tfidf_train_data)

confusion_matrix(train_labels,y_train_pred)

from sklearn.metrics import accuracy_score

accuracy_score(train_labels, y_train_pred)

"""Curatarea datelor de test"""

testData.text = testData.text.map(lambda x: re.sub(r"(@\[A-Za-z0-9]+)|([^0-9A-Za-z \t])|(\w+:\/\/\S+)|^rt|http.+?", "", x))

testData.text = testData.text.map(lambda x: ' '.join([y for y in x.split() if y not in full_stopword_list]))

x_test = testData['text'].to_numpy()
tfidf_test_data = vectorizer.transform(x_test)

"""Prezicerea pe datele de test"""

y_test_pred = cls.predict(tfidf_test_data)

"""Functie pentru transformarea corespondentelor numerice inapoi in labels"""

def label_names(x):
  if x==0:
    return 'England'
  if x==1:
    return 'Ireland'
  if x==2:
    return 'Scotland'

result = pd.DataFrame()
result['id'] = range(1,len(x_test)+1)
result['label'] = y_test_pred
result['label'] = result['label'].map(label_names)

"""Trecerea predictiilor in format CSV"""

result.to_csv('19Nov_1.csv',index=False)